{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31f12064",
   "metadata": {},
   "source": [
    "![MBITSchool](https://i.imgur.com/UiDMkO3.png)\n",
    "\n",
    "### Proyecto de Consolidación APIs y Web Scraping\n",
    "\n",
    "##### Alejandro Paredero - paredero@mbitschool.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bce86a",
   "metadata": {},
   "source": [
    "**El proyecto de consolidación de Web Scraping, API REST y Streamlit pretende que de forma autónoma combinemos proyectos de captura, procesamiento de datos y visualización basados en un sistema o entre dos o más distintos.**\n",
    "\n",
    "Aquí la creatividad es muy importante ✔️. Una vez resuelto los retos propuestos siéntete libre de extenderlos con características adicionales.\n",
    "\n",
    "⚠️ **ATENCIÓN**: <u>Ten a mano las presentaciones y los cuadernos resueltos de las sesiones anteriores, te serán de gran ayuda.</u>\n",
    "\n",
    "**Los ejercicios EXTRA son opcionales**. Si dais vuestro consentimiento tras la fecha de cierre, podré hacer publicaciones con capturas de pantalla en redes como LinkedIn con objeto de promocionaros.\n",
    "\n",
    "Para dudas tenéis un foro en el campus o mi correo electrónico 📧 paredero@mbitschool.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff36f1",
   "metadata": {},
   "source": [
    "**Datos del alumno:**\n",
    "\n",
    "- **Nombre:** `Daniel Herraiz Tello`\n",
    "- **Consentimiento sobre ejercicios EXTRA:** Si realizas el ejercicio, ¿permites que pueda publicar el contenido en foto/vídeo si el resultado es relevante? `SI`\n",
    "- **Comentario:** Tras realizar los diferentes retos, ¿qué te han parecido? ¿qué problemas has encontrado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a641e9",
   "metadata": {},
   "source": [
    "```\n",
    "Escribe tu comentario aquí\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b96a4",
   "metadata": {},
   "source": [
    "### Reto 1 - BeautifulSoup y Streamlit: Capturar estadísticas de equipos de hockey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae7c6b",
   "metadata": {},
   "source": [
    "Vista la web https://www.scrapethissite.com/pages/forms/. Examina como se comporta la URL con la paginación.  El objetivo es capturar la información de las primeras 10 páginas y crear una aplicación sencilla en Streamlit que permita mostrar la información de las columnas \"Team name\", \"Year\", \"Win\", \"Loses\" y \"+/-\"\n",
    "\n",
    "##### Ejercicio:\n",
    "* Captura el los términos listados anteriormente:  \"Team name\", \"Year\", \"Win\", \"Loses\" y \"+/-\" , de al menos las primeras 8 páginas.\n",
    "* Almacena el resultado en un **dataframe** de Steramlit.\n",
    "* Implementa el cacheo de contenido de las URL (Revisa la presentación) para evitar consultas repetidas a las URL.\n",
    "* **Extra**: Permite que el usuario elija el rango de página mínima y máxima a capturar contenido\n",
    "* **Extra**: Permite que el usuario elija filtrar por equipos cuyo \"+/-\" sea superior a una cifra determinada.\n",
    "\n",
    "*PISTA: La página 1 tiene la estructura `https://www.scrapethissite.com/pages/forms/?page_num=1` , la página 2 `https://www.scrapethissite.com/pages/forms/?page_num=2` y así sucesivamente.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60597456",
   "metadata": {},
   "source": [
    "\n",
    "##### Comentarios\n",
    "* Si realizo una búsqueda incorrecta se queda pensando mucho tiempo.\n",
    "* La columna +/- requiere especial atención y me ha dado algunos problemas al variar el nombre de la clase según >0 o <0\n",
    "* Al obtener el rango de páginas, a veces se queda bloqueado y tengo que reiniciar el kernel, sin un patrón claro. Añadiendo retraso entre llamadas tampoco se arregla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf0f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca18ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo un diccionario con el nº de la página como clave y el contenido como valor\n",
    "cachedPageContent = {}\n",
    "#función para obtener el contenido de la página de cache o via request\n",
    "def getPageContent (pageNumber):\n",
    "    if pageNumber in cachedPageContent:\n",
    "        print(f\"pag {pageNumber} obtenida desde cache\")\n",
    "        return cachedPageContent[pageNumber]\n",
    "    else:  \n",
    "        time.sleep(0.2)\n",
    "        url = f\"https://www.scrapethissite.com/pages/forms/?page_num={pageNumber}\"\n",
    "        page = requests.get(url)\n",
    "        if page.status_code != 200:\n",
    "            raise Exception(f\"Expected 200, got {page.status_code}\")\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        cachedPageContent[pageNumber] = soup\n",
    "        return soup  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d3932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#función para obtener el dataframe de una página\n",
    "def getDfFromPage (pageNumber, minGoalDif):\n",
    "    table = getPageContent(pageNumber).find(\"table\", class_=\"table\")\n",
    "    #Puedo extraer todas las columnas\n",
    "    columnNames = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "    #O forzar las columnas sugeridas \n",
    "    columnNames = [\"Team name\",\"Year\",\"Wins\",\"Losses\",\"+/-\"]\n",
    "    #Extraigo las filas\n",
    "    rows = table.find_all(\"tr\", class_=\"team\")\n",
    "    #Extraigo la información de cada campo en cada fila\n",
    "    teams = []\n",
    "    for row in rows:\n",
    "        #Extra; primero aplico el filtro +/-\n",
    "        if int(row.find(\"td\", class_=re.compile(\"diff\")).get_text(strip=True)) > minGoalDif:\n",
    "            #filtro por tag y por clase teniendo en cuenta las columnas solicitadas\n",
    "            values = [td.get_text(strip=True) for td in row.find_all(\"td\", class_=[\"name\",\"year\",\"wins\",\"losses\",re.compile(\"diff\")])]\n",
    "            teams.append(values)  \n",
    "    return pd.DataFrame(teams, columns=columnNames) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c056506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35\n",
      "[['-35']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  -35"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testteams = []\n",
    "htmltest = \"\"\"                       <td class=\"diff text-success\">\n",
    "                            -35\n",
    "                        </td>\"\"\"\n",
    "soup = BeautifulSoup(htmltest, 'html.parser')\n",
    "all_text = soup.get_text(strip=True)\n",
    "print(all_text)\n",
    "valuestest = [td.get_text(strip=True) for td in soup.find_all(\"td\", class_=[\"name\",\"year\",\"wins\",\"losses\",\"diff text-success\"])]\n",
    "testteams.append(valuestest)  \n",
    "print(testteams)\n",
    "testdf = pd.DataFrame(testteams)\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2b4601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para obtener un dataframe obtenido de un rango de páginas\n",
    "def getDfFromPageRange (firstPage, lastPage, minGoalDif):\n",
    "    resultDf = pd.DataFrame()\n",
    "    #try:\n",
    "    for i in range(firstPage, lastPage + 1):\n",
    "        pageDf = getDfFromPage(i,minGoalDif)\n",
    "        if resultDf.empty:\n",
    "            resultDf = pageDf.copy()\n",
    "        else:\n",
    "            resultDf = pd.concat([resultDf, pageDf], ignore_index = True)\n",
    "    #except Exception:\n",
    "        #print (\"Rango inválido de páginas, prueba otros valores\")\n",
    "    return resultDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2886184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>+/-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston Bruins</td>\n",
       "      <td>1990</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>1990</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago Blackhawks</td>\n",
       "      <td>1990</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Angeles Kings</td>\n",
       "      <td>1990</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montreal Canadiens</td>\n",
       "      <td>1990</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New York Rangers</td>\n",
       "      <td>1990</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pittsburgh Penguins</td>\n",
       "      <td>1990</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>St. Louis Blues</td>\n",
       "      <td>1990</td>\n",
       "      <td>47</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chicago Blackhawks</td>\n",
       "      <td>1991</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team name  Year Wins Losses +/-\n",
       "0        Boston Bruins  1990   44     24  35\n",
       "1       Calgary Flames  1990   46     26  81\n",
       "2   Chicago Blackhawks  1990   49     23  73\n",
       "3    Los Angeles Kings  1990   46     24  86\n",
       "4   Montreal Canadiens  1990   39     30  24\n",
       "5     New York Rangers  1990   36     31  32\n",
       "6  Pittsburgh Penguins  1990   41     33  37\n",
       "7      St. Louis Blues  1990   47     22  60\n",
       "8   Chicago Blackhawks  1991   36     29  21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pag1 = getDfFromPage(1, 15)\n",
    "print(df_pag1.shape)\n",
    "df_pag1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b46c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pag 1 obtenida desde cache\n",
      "pag 2 obtenida desde cache\n",
      "pag 3 obtenida desde cache\n",
      "pag 4 obtenida desde cache\n",
      "pag 5 obtenida desde cache\n",
      "pag 6 obtenida desde cache\n",
      "pag 7 obtenida desde cache\n",
      "pag 8 obtenida desde cache\n",
      "(77, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>+/-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston Bruins</td>\n",
       "      <td>1990</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>1990</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago Blackhawks</td>\n",
       "      <td>1990</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Angeles Kings</td>\n",
       "      <td>1990</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montreal Canadiens</td>\n",
       "      <td>1990</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team name  Year Wins Losses +/-\n",
       "0       Boston Bruins  1990   44     24  35\n",
       "1      Calgary Flames  1990   46     26  81\n",
       "2  Chicago Blackhawks  1990   49     23  73\n",
       "3   Los Angeles Kings  1990   46     24  86\n",
       "4  Montreal Canadiens  1990   39     30  24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_pag1_8 = getDfFromPageRange(1,8,15)\n",
    "print(df_pag1_8.shape)\n",
    "df_pag1_8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33da1d1",
   "metadata": {},
   "source": [
    "### Reto 2 - Selenium: Captura del valor del oro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e85677",
   "metadata": {},
   "source": [
    "Como vimos en clase, hay páginas que implementan medidas para evitar el Web Scraping. En la web de https://www.inversoro.es/precio-del-oro/precio-oro-hoy/ apreciamos cómo la página web cara un valor antiguo y pasados unos segundos actualiza. \n",
    "\n",
    "Esto hace que bibliotecas como `request` + `BeautifulSoup` no nos sirva aquí ya que capturamos el instante t=0. Sin embargo, con *Selenium* podemos interactuar en tiempo real mientras el navegador se ejecuta.\n",
    "\n",
    "#### Ejercicio\n",
    "Inspecciona la web, obteniendo la etiqueta HTML donde el valor aparece representado y crea un script que utilice Selenium, cargando la página y capturando  dicho valor en tiempo real cada 5 segundos en un periodo de 1 minuto. Almacena el resultado de dicho valor y del timestamp correspondiente (*[ayuda](https://www.geeksforgeeks.org/get-current-timestamp-using-python/)*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d374af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e60b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153c959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f60755b",
   "metadata": {},
   "source": [
    "### Reto EXTRA - Selenium, BeautifulSoup y Streamlit: El comparador (simple) de precios 📊📉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538731",
   "metadata": {},
   "source": [
    "Los comparadores de precios <u>es uno de los nichos de mercado más lucrativos en Internet.</u> Dado un producto o servicio a nivel de usuario nos beneficiamos del precio más bajo existente y a nivel de empresa éstas obtienen grandes beneficios gracias a sistemas de referidos o de comisiones por venta realizada.\n",
    "\n",
    "En esta ocasión vamos a realizar un simple comparador de precios basado en el número ISBN. Un ISBN es un código normalizado internacional para libros (International Standard Book Number). Estos estaban compuestos por 10 dígitos hasta diciembre de 2006 pero, desde enero de 2007, tienen una extensión de 13 dígitos. \n",
    "\n",
    "\n",
    "Por ejemplo, el ISBN [9788478884452](https://www.google.es/search?q=9788478884452) (haz click) corresponde al libro \"Harry Potter y la piedra filosofal\".\n",
    "\n",
    "Dado que no disponemos de acceso a APIs de las tiendas principales <u>capturaremos el precio a través de técnicas de Web Sraping.</u>\n",
    "\n",
    "##### Ejercicio \n",
    "\n",
    "El objetivo es realizar la consulta de un ISBN, por ejemplo el de \"Harry Potter y la Piedra filosofal\" en al menos **tres** de las siguientes tiendas propuestas. Captura el primer resultado en EUROS, y devuelve cómo resultado cuál tiene el precio más bajo. \n",
    "\n",
    "Crea un sencillo interfaz en Streamlit que pregunte por el ISBN de un número (entre 10 y 13 dígitos) y devuelva como resultado el primer elemento de cada tienda examinada, con el título, la imagen (si la hubiese), el precio y un enlace para hacer click.\n",
    "\n",
    "Como puntos extra:\n",
    "* Incluye en la comparativa más de las 3 tiendas propuestas.\n",
    "* Incluye por texto posteriormente cuál es la diferencia de precio en euros y en porcentaje respecto al valor más bajo detectado para saber cuánto nos estamos ahorrando.\n",
    "* Crea un diagrama de barras con el precio en cada tienda para representar visualmente el ahorro en precio.\n",
    "\n",
    "Ejemplo de tiendas propuestas:\n",
    "- https://www.casadellibro.com/\n",
    "- https://www.libreriacentral.com/\n",
    "- https://www.iberlibro.com/\n",
    "- https://www.amazon.es/\n",
    "- https://ebay.es\n",
    "- https://www.elcorteingles.es/\n",
    "\n",
    "Recuerda que para cada página debes realizar ingeniería inversa, averiguando cómo se comportan las URLs de cada sitio web para hacer una búsqueda directa.\n",
    "\n",
    "**Pista**: Utiliza Selenium para capturar datos si te resulta request/BeautifulSoup complicado de utilizar.\n",
    "\n",
    "**Extra**: *¿Conoces alguna otra página donde comprar libros? Inclúyela en el comprador*\n",
    "\n",
    "**Extra 2**: *¿Cómo podríamos obtener una evolución del precio durante una semana?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import streamlit as st\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTREGA AQUÍ EL CÓDIGO PYTHON DE LA APLICACIÓN STREAMLIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
