{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31f12064",
   "metadata": {},
   "source": [
    "![MBITSchool](https://i.imgur.com/UiDMkO3.png)\n",
    "\n",
    "### Proyecto de Consolidaci√≥n APIs y Web Scraping\n",
    "\n",
    "##### Alejandro Paredero - paredero@mbitschool.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bce86a",
   "metadata": {},
   "source": [
    "**El proyecto de consolidaci√≥n de Web Scraping, API REST y Streamlit pretende que de forma aut√≥noma combinemos proyectos de captura, procesamiento de datos y visualizaci√≥n basados en un sistema o entre dos o m√°s distintos.**\n",
    "\n",
    "Aqu√≠ la creatividad es muy importante ‚úîÔ∏è. Una vez resuelto los retos propuestos si√©ntete libre de extenderlos con caracter√≠sticas adicionales.\n",
    "\n",
    "‚ö†Ô∏è **ATENCI√ìN**: <u>Ten a mano las presentaciones y los cuadernos resueltos de las sesiones anteriores, te ser√°n de gran ayuda.</u>\n",
    "\n",
    "**Los ejercicios EXTRA son opcionales**. Si dais vuestro consentimiento tras la fecha de cierre, podr√© hacer publicaciones con capturas de pantalla en redes como LinkedIn con objeto de promocionaros.\n",
    "\n",
    "Para dudas ten√©is un foro en el campus o mi correo electr√≥nico üìß paredero@mbitschool.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff36f1",
   "metadata": {},
   "source": [
    "**Datos del alumno:**\n",
    "\n",
    "- **Nombre:** `Daniel Herraiz Tello`\n",
    "- **Consentimiento sobre ejercicios EXTRA:** Si realizas el ejercicio, ¬øpermites que pueda publicar el contenido en foto/v√≠deo si el resultado es relevante? `SI`\n",
    "- **Comentario:** Tras realizar los diferentes retos, ¬øqu√© te han parecido? ¬øqu√© problemas has encontrado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a641e9",
   "metadata": {},
   "source": [
    "```\n",
    "Escribe tu comentario aqu√≠\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b96a4",
   "metadata": {},
   "source": [
    "### Reto 1 - BeautifulSoup y Streamlit: Capturar estad√≠sticas de equipos de hockey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae7c6b",
   "metadata": {},
   "source": [
    "Vista la web https://www.scrapethissite.com/pages/forms/. Examina como se comporta la URL con la paginaci√≥n.  El objetivo es capturar la informaci√≥n de las primeras 10 p√°ginas y crear una aplicaci√≥n sencilla en Streamlit que permita mostrar la informaci√≥n de las columnas \"Team name\", \"Year\", \"Win\", \"Loses\" y \"+/-\"\n",
    "\n",
    "##### Ejercicio:\n",
    "* Captura el los t√©rminos listados anteriormente:  \"Team name\", \"Year\", \"Win\", \"Loses\" y \"+/-\" , de al menos las primeras 8 p√°ginas.\n",
    "* Almacena el resultado en un **dataframe** de Steramlit.\n",
    "* Implementa el cacheo de contenido de las URL (Revisa la presentaci√≥n) para evitar consultas repetidas a las URL.\n",
    "* **Extra**: Permite que el usuario elija el rango de p√°gina m√≠nima y m√°xima a capturar contenido\n",
    "* **Extra**: Permite que el usuario elija filtrar por equipos cuyo \"+/-\" sea superior a una cifra determinada.\n",
    "\n",
    "*PISTA: La p√°gina 1 tiene la estructura `https://www.scrapethissite.com/pages/forms/?page_num=1` , la p√°gina 2 `https://www.scrapethissite.com/pages/forms/?page_num=2` y as√≠ sucesivamente.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f8b5520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\danie\\appdata\\roaming\\python\\python313\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\danie\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danie\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danie\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danie\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60597456",
   "metadata": {},
   "source": [
    "Comentarios\n",
    "Si realizo una b√∫squeda incorrecta se queda pensando mucho tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abf0f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799b9eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"https://www.scrapethissite.com/pages/forms/\")\n",
    "print(type(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab0a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardo el html de la p√°gina en un archivo para revisarlo y acceder con facilidad\n",
    "with open(\"rawPage.txt\", \"w\") as file:\n",
    "    file.write(page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111340ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"https://www.scrapethissite.com/pages/forms/\")\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ed98375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Team Name', 'Year', 'Wins', 'Losses', 'OT Losses', 'Win %', 'Goals For (GF)', 'Goals Against (GA)', '+ / -']\n"
     ]
    }
   ],
   "source": [
    "#Extraigo la tabla primero\n",
    "table = soup.find(\"table\", class_=\"table\")\n",
    "#Extraigo y limpio las columnas\n",
    "columnNames = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "print(columnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eb54610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraigo las filas\n",
    "rows = table.find_all(\"tr\", class_=\"team\")\n",
    "#Extraigo la informaci√≥n de cada campo en cada fila\n",
    "teams = []\n",
    "for row in rows:\n",
    "    values = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "    teams.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93d71888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>OT Losses</th>\n",
       "      <th>Win %</th>\n",
       "      <th>Goals For (GF)</th>\n",
       "      <th>Goals Against (GA)</th>\n",
       "      <th>+ / -</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston Bruins</td>\n",
       "      <td>1990</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td></td>\n",
       "      <td>0.55</td>\n",
       "      <td>299</td>\n",
       "      <td>264</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buffalo Sabres</td>\n",
       "      <td>1990</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.388</td>\n",
       "      <td>292</td>\n",
       "      <td>278</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>1990</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td></td>\n",
       "      <td>0.575</td>\n",
       "      <td>344</td>\n",
       "      <td>263</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicago Blackhawks</td>\n",
       "      <td>1990</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>0.613</td>\n",
       "      <td>284</td>\n",
       "      <td>211</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detroit Red Wings</td>\n",
       "      <td>1990</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "      <td>0.425</td>\n",
       "      <td>273</td>\n",
       "      <td>298</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Name  Year Wins Losses OT Losses  Win % Goals For (GF)  \\\n",
       "0       Boston Bruins  1990   44     24             0.55            299   \n",
       "1      Buffalo Sabres  1990   31     30            0.388            292   \n",
       "2      Calgary Flames  1990   46     26            0.575            344   \n",
       "3  Chicago Blackhawks  1990   49     23            0.613            284   \n",
       "4   Detroit Red Wings  1990   34     38            0.425            273   \n",
       "\n",
       "  Goals Against (GA) + / -  \n",
       "0                264    35  \n",
       "1                278    14  \n",
       "2                263    81  \n",
       "3                211    73  \n",
       "4                298   -25  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Asocio a un dataframe\n",
    "teamsdf = pd.DataFrame(teams, columns=columnNames)\n",
    "teamsdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33da1d1",
   "metadata": {},
   "source": [
    "### Reto 2 - Selenium: Captura del valor del oro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e85677",
   "metadata": {},
   "source": [
    "Como vimos en clase, hay p√°ginas que implementan medidas para evitar el Web Scraping. En la web de https://www.inversoro.es/precio-del-oro/precio-oro-hoy/ apreciamos c√≥mo la p√°gina web cara un valor antiguo y pasados unos segundos actualiza. \n",
    "\n",
    "Esto hace que bibliotecas como `request` + `BeautifulSoup` no nos sirva aqu√≠ ya que capturamos el instante t=0. Sin embargo, con *Selenium* podemos interactuar en tiempo real mientras el navegador se ejecuta.\n",
    "\n",
    "#### Ejercicio\n",
    "Inspecciona la web, obteniendo la etiqueta HTML donde el valor aparece representado y crea un script que utilice Selenium, cargando la p√°gina y capturando  dicho valor en tiempo real cada 5 segundos en un periodo de 1 minuto. Almacena el resultado de dicho valor y del timestamp correspondiente (*[ayuda](https://www.geeksforgeeks.org/get-current-timestamp-using-python/)*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d374af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e60b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153c959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f60755b",
   "metadata": {},
   "source": [
    "### Reto EXTRA - Selenium, BeautifulSoup y Streamlit: El comparador (simple) de precios üìäüìâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538731",
   "metadata": {},
   "source": [
    "Los comparadores de precios <u>es uno de los nichos de mercado m√°s lucrativos en Internet.</u> Dado un producto o servicio a nivel de usuario nos beneficiamos del precio m√°s bajo existente y a nivel de empresa √©stas obtienen grandes beneficios gracias a sistemas de referidos o de comisiones por venta realizada.\n",
    "\n",
    "En esta ocasi√≥n vamos a realizar un simple comparador de precios basado en el n√∫mero ISBN. Un ISBN es un c√≥digo normalizado internacional para libros (International Standard Book Number). Estos estaban compuestos por 10 d√≠gitos hasta diciembre de 2006 pero, desde enero de 2007, tienen una extensi√≥n de 13 d√≠gitos. \n",
    "\n",
    "\n",
    "Por ejemplo, el ISBN [9788478884452](https://www.google.es/search?q=9788478884452) (haz click) corresponde al libro \"Harry Potter y la piedra filosofal\".\n",
    "\n",
    "Dado que no disponemos de acceso a APIs de las tiendas principales <u>capturaremos el precio a trav√©s de t√©cnicas de Web Sraping.</u>\n",
    "\n",
    "##### Ejercicio \n",
    "\n",
    "El objetivo es realizar la consulta de un ISBN, por ejemplo el de \"Harry Potter y la Piedra filosofal\" en al menos **tres** de las siguientes tiendas propuestas. Captura el primer resultado en EUROS, y devuelve c√≥mo resultado cu√°l tiene el precio m√°s bajo. \n",
    "\n",
    "Crea un sencillo interfaz en Streamlit que pregunte por el ISBN de un n√∫mero (entre 10 y 13 d√≠gitos) y devuelva como resultado el primer elemento de cada tienda examinada, con el t√≠tulo, la imagen (si la hubiese), el precio y un enlace para hacer click.\n",
    "\n",
    "Como puntos extra:\n",
    "* Incluye en la comparativa m√°s de las 3 tiendas propuestas.\n",
    "* Incluye por texto posteriormente cu√°l es la diferencia de precio en euros y en porcentaje respecto al valor m√°s bajo detectado para saber cu√°nto nos estamos ahorrando.\n",
    "* Crea un diagrama de barras con el precio en cada tienda para representar visualmente el ahorro en precio.\n",
    "\n",
    "Ejemplo de tiendas propuestas:\n",
    "- https://www.casadellibro.com/\n",
    "- https://www.libreriacentral.com/\n",
    "- https://www.iberlibro.com/\n",
    "- https://www.amazon.es/\n",
    "- https://ebay.es\n",
    "- https://www.elcorteingles.es/\n",
    "\n",
    "Recuerda que para cada p√°gina debes realizar ingenier√≠a inversa, averiguando c√≥mo se comportan las URLs de cada sitio web para hacer una b√∫squeda directa.\n",
    "\n",
    "**Pista**: Utiliza Selenium para capturar datos si te resulta request/BeautifulSoup complicado de utilizar.\n",
    "\n",
    "**Extra**: *¬øConoces alguna otra p√°gina donde comprar libros? Incl√∫yela en el comprador*\n",
    "\n",
    "**Extra 2**: *¬øC√≥mo podr√≠amos obtener una evoluci√≥n del precio durante una semana?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import streamlit as st\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTREGA AQU√ç EL C√ìDIGO PYTHON DE LA APLICACI√ìN STREAMLIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
